{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMJWY9tQFqmOqAWv59bSZQC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inbalhasar/NLP_project/blob/main/gemini_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfvTlH2nFRf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2042a2f-ce19-412c-a1cd-f1ea5b96e6ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('/content/drive/MyDrive/gemini_runs', exist_ok=True)"
      ],
      "metadata": {
        "id": "GJOQbzSbFZAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyAUjvCwbwUS78Lw59OCUHWNiU9v44PCUfw\""
      ],
      "metadata": {
        "id": "HYHQPqraFmBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== AI/Human full-dataset runner (local save, no Drive) ====\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from google import genai\n",
        "\n",
        "# --------- EDIT THESE IF NEEDED ----------\n",
        "# Your CSV path in Colab. If you uploaded the file via the Files panel or files.upload(), /content is correct.\n",
        "PATH = \"/content/ai_human_content_detection_dataset.csv\"\n",
        "\n",
        "# Column names in your CSV\n",
        "TEXT_COL  = \"text_content\"   # text column\n",
        "LABEL_COL = \"label\"          # 1 = AI, 0 = Human\n",
        "\n",
        "# Model to use\n",
        "MODEL_NAME = \"gemini-2.0-flash\"   # or \"gemini-2.5-flash\"\n",
        "\n",
        "PROGRESS_CSV_PATH = \"/content/drive/MyDrive/gemini_runs/predictions_progress.csv\"\n",
        "REQUEST_LOG_PATH  = \"/content/drive/MyDrive/gemini_runs/gemini_request_log_8.json\"\n",
        "\n",
        "\n",
        "# Free-tier daily cap (adjust if Google changes limits)\n",
        "DAILY_LIMIT = 200\n",
        "# -----------------------------------------\n",
        "\n",
        "# If you prefer to pass the key explicitly, uncomment the next line:\n",
        "# client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "def load_request_log(path=REQUEST_LOG_PATH):\n",
        "    \"\"\"Load (and reset if date changed) the daily request counter (UTC).\"\"\"\n",
        "    today = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
        "    if os.path.exists(path):\n",
        "        try:\n",
        "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "                data = json.load(f)\n",
        "        except Exception:\n",
        "            data = {}\n",
        "    else:\n",
        "        data = {}\n",
        "    if data.get(\"date\") != today:\n",
        "        data = {\"date\": today, \"count\": 0}\n",
        "    return data\n",
        "\n",
        "def save_request_log(data, path=REQUEST_LOG_PATH):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "def load_progress(path=PROGRESS_CSV_PATH):\n",
        "    \"\"\"Read prior predictions if present; otherwise return an empty frame.\"\"\"\n",
        "    if os.path.exists(path):\n",
        "        return pd.read_csv(path)\n",
        "    cols = [\"row_id\", \"pred_label\", \"raw_response\", \"explanation\", \"model_name\", \"timestamp_utc\"]\n",
        "    return pd.DataFrame(columns=cols)\n",
        "\n",
        "def save_progress(df_prog, path=PROGRESS_CSV_PATH):\n",
        "    df_prog.to_csv(path, index=False)\n",
        "\n",
        "def parse_decision(resp_text: str):\n",
        "    \"\"\"\n",
        "    Extract 'AI' or 'Human' from the model response.\n",
        "    Expects the model to put the label on the first line.\n",
        "    \"\"\"\n",
        "    if not resp_text:\n",
        "        return None\n",
        "    lines = [ln.strip() for ln in resp_text.strip().splitlines() if ln.strip()]\n",
        "    if lines:\n",
        "        first = lines[0].lower()\n",
        "        if re.search(r\"\\bai\\b\", first):\n",
        "            return \"AI\"\n",
        "        if re.search(r\"\\bhuman\\b\", first):\n",
        "            return \"Human\"\n",
        "    # Fallbacks\n",
        "    lower = resp_text.lower()\n",
        "    if re.search(r\"(label|prediction|answer)\\s*[:\\-]\\s*ai\\b\", lower):\n",
        "        return \"AI\"\n",
        "    if re.search(r\"(label|prediction|answer)\\s*[:\\-]\\s*human\\b\", lower):\n",
        "        return \"Human\"\n",
        "    if re.search(r\"\\bai\\b\", lower):\n",
        "        return \"AI\"\n",
        "    if re.search(r\"\\bhuman\\b\", lower):\n",
        "        return \"Human\"\n",
        "    return None\n",
        "\n",
        "def decision_to_int(decision: str):\n",
        "    \"\"\"Map 'AI' -> 1, 'Human' -> 0, else None.\"\"\"\n",
        "    if decision is None:\n",
        "        return None\n",
        "    d = decision.strip().lower()\n",
        "    return 1 if d == \"ai\" else 0 if d == \"human\" else None\n",
        "\n",
        "def call_gemini_with_backoff(client, prompt, model=MODEL_NAME, max_retries=5):\n",
        "    \"\"\"Retry on rate-limit/quota errors with exponential backoff.\"\"\"\n",
        "    delay = 2.0\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            return client.models.generate_content(model=model, contents=prompt)\n",
        "        except Exception as e:\n",
        "            m = str(e).lower()\n",
        "            if any(k in m for k in [\"rate\", \"quota\", \"429\", \"too many requests\", \"exceed\"]):\n",
        "                if attempt == max_retries - 1:\n",
        "                    raise\n",
        "                time.sleep(delay)\n",
        "                delay = min(delay * 2, 60)\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "def main():\n",
        "    # 1) Load dataset\n",
        "    df = pd.read_csv(PATH)\n",
        "    if TEXT_COL not in df.columns or LABEL_COL not in df.columns:\n",
        "        raise ValueError(f\"Columns '{TEXT_COL}' and/or '{LABEL_COL}' not found in CSV.\")\n",
        "    df = df[[TEXT_COL, LABEL_COL]].dropna().reset_index().rename(columns={\"index\": \"row_id\"})\n",
        "\n",
        "    # 2) Load progress and daily counter\n",
        "    progress = load_progress()\n",
        "    req_log = load_request_log()\n",
        "\n",
        "    done_ids = set(progress[\"row_id\"].astype(int)) if not progress.empty else set()\n",
        "    pending = df[~df[\"row_id\"].isin(done_ids)].copy()\n",
        "\n",
        "    remaining = max(0, DAILY_LIMIT - int(req_log.get(\"count\", 0)))\n",
        "    if remaining == 0:\n",
        "        print(f\"Daily quota reached ({DAILY_LIMIT}). Try again tomorrow.\")\n",
        "        merged = df.merge(progress[[\"row_id\", \"pred_label\"]], on=\"row_id\", how=\"left\")\n",
        "        evaluated = merged.dropna(subset=[\"pred_label\"]).copy()\n",
        "        if not evaluated.empty:\n",
        "            evaluated[\"correct\"] = (evaluated[\"pred_label\"].astype(int) == evaluated[LABEL_COL].astype(int))\n",
        "            print(f\"Total evaluated so far: {len(evaluated)} | Correct: {evaluated['correct'].sum()} \"\n",
        "                  f\"| Accuracy: {evaluated['correct'].mean():.3f}\")\n",
        "        return\n",
        "\n",
        "    if pending.empty:\n",
        "        print(\"No pending rows. Everything is already evaluated.\")\n",
        "        merged = df.merge(progress[[\"row_id\", \"pred_label\"]], on=\"row_id\", how=\"left\")\n",
        "        evaluated = merged.dropna(subset=[\"pred_label\"]).copy()\n",
        "        if not evaluated.empty:\n",
        "            evaluated[\"correct\"] = (evaluated[\"pred_label\"].astype(int) == evaluated[LABEL_COL].astype(int))\n",
        "            print(f\"Total evaluated: {len(evaluated)} | Correct: {evaluated['correct'].sum()} \"\n",
        "                  f\"| Accuracy: {evaluated['correct'].mean():.3f}\")\n",
        "        return\n",
        "\n",
        "    to_run_now = min(remaining, len(pending))\n",
        "    work_batch = pending.head(to_run_now).copy()\n",
        "    print(f\"Pending rows: {len(pending)} | Running now: {to_run_now} | Remaining daily quota before run: {remaining}\")\n",
        "\n",
        "    client = genai.Client()\n",
        "\n",
        "    new_rows = []\n",
        "    done_this_run = 0\n",
        "\n",
        "    for _, row in work_batch.iterrows():\n",
        "        row_id = int(row[\"row_id\"])\n",
        "        text = str(row[TEXT_COL])\n",
        "\n",
        "        prompt = (\n",
        "            \"Decide if the following text was likely written by an AI or a human.\\n\"\n",
        "            \"FIRST line: output ONLY one word — 'AI' or 'Human'.\\n\"\n",
        "            \"SECOND line: a short explanation.\\n\\n\"\n",
        "            f\"{text}\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            resp = call_gemini_with_backoff(client, prompt, model=MODEL_NAME)\n",
        "            resp_text = getattr(resp, \"text\", None)\n",
        "        except Exception:\n",
        "            resp_text = None\n",
        "\n",
        "        decision = parse_decision(resp_text or \"\")\n",
        "        pred_int = decision_to_int(decision)\n",
        "\n",
        "        # Extract a brief explanation (2nd line if present), else the whole text\n",
        "        explanation = None\n",
        "        if resp_text:\n",
        "            lines = resp_text.strip().splitlines()\n",
        "            explanation = lines[1].strip() if len(lines) >= 2 else resp_text.strip()\n",
        "\n",
        "        new_rows.append({\n",
        "            \"row_id\": row_id,\n",
        "            \"pred_label\": pred_int,\n",
        "            \"raw_response\": resp_text,\n",
        "            \"explanation\": explanation,\n",
        "            \"model_name\": MODEL_NAME,\n",
        "            \"timestamp_utc\": datetime.utcnow().isoformat(timespec=\"seconds\")\n",
        "        })\n",
        "\n",
        "        # Update counter and periodically flush to disk\n",
        "        req_log[\"count\"] = int(req_log.get(\"count\", 0)) + 1\n",
        "        done_this_run += 1\n",
        "\n",
        "        if done_this_run % 10 == 0:\n",
        "            progress = pd.concat([progress, pd.DataFrame(new_rows)], ignore_index=True)\n",
        "            save_progress(progress, PROGRESS_CSV_PATH)\n",
        "            save_request_log(req_log, REQUEST_LOG_PATH)\n",
        "            new_rows = []\n",
        "\n",
        "        if req_log[\"count\"] >= DAILY_LIMIT:\n",
        "            print(f\"Reached daily limit ({DAILY_LIMIT}). Stopping.\")\n",
        "            break\n",
        "\n",
        "    if new_rows:\n",
        "        progress = pd.concat([progress, pd.DataFrame(new_rows)], ignore_index=True)\n",
        "    save_progress(progress, PROGRESS_CSV_PATH)\n",
        "    save_request_log(req_log, REQUEST_LOG_PATH)\n",
        "\n",
        "    # Accuracy reports\n",
        "    merged_all = df.merge(progress[[\"row_id\", \"pred_label\"]], on=\"row_id\", how=\"left\")\n",
        "    evaluated_all = merged_all.dropna(subset=[\"pred_label\"]).copy()\n",
        "    if not evaluated_all.empty:\n",
        "        evaluated_all[\"correct\"] = (evaluated_all[\"pred_label\"].astype(int) == evaluated_all[LABEL_COL].astype(int))\n",
        "        total_correct = int(evaluated_all[\"correct\"].sum())\n",
        "        total_eval = len(evaluated_all)\n",
        "        total_acc = total_correct / total_eval if total_eval else 0.0\n",
        "        print(f\"[Overall] Evaluated: {total_eval} | Correct: {total_correct} | Accuracy: {total_acc:.3f}\")\n",
        "\n",
        "    if done_this_run > 0:\n",
        "        processed_ids_this_run = set(work_batch[\"row_id\"].tolist()[:done_this_run])\n",
        "        eval_this = evaluated_all[evaluated_all[\"row_id\"].isin(processed_ids_this_run)].copy()\n",
        "        if not eval_this.empty:\n",
        "            correct_this = int(eval_this[\"correct\"].sum())\n",
        "            acc_this = correct_this / len(eval_this)\n",
        "            print(f\"[This run] Evaluated: {len(eval_this)} | Correct: {correct_this} | Accuracy: {acc_this:.3f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "JRuVH8D_FrP3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7bcf9ab-47e4-4cfb-fb6d-f5dc61017759"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-156331783.py:34: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  today = datetime.utcnow().strftime(\"%Y-%m-%d\")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pending rows: 167 | Running now: 167 | Remaining daily quota before run: 200\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-156331783.py:186: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp_utc\": datetime.utcnow().isoformat(timespec=\"seconds\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Overall] Evaluated: 1303 | Correct: 655 | Accuracy: 0.503\n",
            "[This run] Evaluated: 158 | Correct: 2 | Accuracy: 0.013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fKEi6339FpSB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}